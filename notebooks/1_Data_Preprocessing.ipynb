{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba6af30",
   "metadata": {},
   "source": [
    "<span style=\"color:gray\">\n",
    "Fraunhofer Institute for Integrated Circuits IIS, Division Engineering of Adaptive Systems EAS<br>\n",
    "Münchner Straße 16, 01187 Dresden, Germany\n",
    "</span>\n",
    "\n",
    "---\n",
    "\n",
    "## ESB - Energy Saving by Blockchain\n",
    "\n",
    "---\n",
    "\n",
    "## Detection of Electric Vehicles and Photovoltaic Systems in Smart Meter Data\n",
    "\n",
    "---\n",
    "\n",
    "# 1: Data Preprocessing\n",
    "\n",
    "\n",
    "This notebook imports the time series from the Pecan Street dataset and the EV charging events from the ACN dataset. This is followed by the artificial addition of electric vehicle charging on selected California households from the Pecan Street dataset\n",
    "\n",
    "### Requirements for running the notebook:\n",
    "\n",
    "1. Pecan Street Dataset: Register at https://dataport.pecanstreet.org/ and download the following three csv files:\n",
    "    * 15minute_data_newyork.csv\n",
    "    * 15minute_data_california.csv\n",
    "    * 15minute_data_austin.csv\n",
    "\n",
    "\n",
    "2. ACN Dataset: Register at https://ev.caltech.edu/register and receive a access token to download the electric vehicle charging events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import base64\n",
    "import json\n",
    "import random\n",
    "\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d118f2",
   "metadata": {},
   "source": [
    "#### Import the smart meter datasets of the Pecan Street Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=''\n",
    "\n",
    "newyork = pd.read_csv (path + '15minute_data_newyork.csv', header=0, sep=',',decimal=\".\")\n",
    "california = pd.read_csv (path + '15minute_data_california.csv', header=0, sep=',',decimal=\".\")\n",
    "austin = pd.read_csv (path + '15minute_data_austin.csv', header=0, sep=',',decimal=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575951f9",
   "metadata": {},
   "source": [
    "#### Sort data by the columns 'dataid' and 'local_15min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33252ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newyork = newyork[['dataid', 'local_15min','grid','car1','car2','solar','solar2']].sort_values(['dataid', 'local_15min']).fillna(0).reset_index(drop=True)\n",
    "california = california[['dataid', 'local_15min','grid','car1','car2','solar','solar2']].sort_values(['dataid', 'local_15min']).fillna(0).reset_index(drop=True)\n",
    "austin = austin[['dataid', 'local_15min','grid','car1','car2','solar','solar2']].sort_values(['dataid', 'local_15min']).fillna(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb5fa6c",
   "metadata": {},
   "source": [
    "#### Convert the column 'local_15min' to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfac304",
   "metadata": {},
   "outputs": [],
   "source": [
    "newyork['local_15min'] = pd.to_datetime(newyork['local_15min'], format='%Y-%m-%d %H:%M:%S-%f')\n",
    "california['local_15min'] = pd.to_datetime(california['local_15min'], format='%Y-%m-%d %H:%M:%S-%f')\n",
    "austin['local_15min'] = pd.to_datetime(austin['local_15min'], format='%Y-%m-%d %H:%M:%S-%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f951c1",
   "metadata": {},
   "source": [
    "#### Group data into an hourly sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cfa082",
   "metadata": {},
   "outputs": [],
   "source": [
    "newyork = newyork.set_index('local_15min').groupby(['dataid',pd.Grouper(freq='1h')]).agg({'grid': 'mean', \n",
    "                                                                                        'car1':'mean', \n",
    "                                                                                        'car2':'mean', \n",
    "                                                                                        'solar': 'mean',\n",
    "                                                                                        'solar2': 'mean'}).reset_index()\n",
    "\n",
    "california = california.set_index('local_15min').groupby(['dataid',pd.Grouper(freq='1h')]).agg({'grid': 'mean', \n",
    "                                                                                        'car1':'mean', \n",
    "                                                                                        'car2':'mean', \n",
    "                                                                                        'solar': 'mean',\n",
    "                                                                                        'solar2': 'mean'}).reset_index()\n",
    "\n",
    "austin = austin.set_index('local_15min').groupby(['dataid',pd.Grouper(freq='1h')]).agg({'grid': 'mean', \n",
    "                                                                                        'car1':'mean', \n",
    "                                                                                        'car2':'mean', \n",
    "                                                                                        'solar': 'mean',\n",
    "                                                                                        'solar2': 'mean'}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5edf3",
   "metadata": {},
   "source": [
    "#### Insert ACN Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4639079",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed621a3",
   "metadata": {},
   "source": [
    "#### Download charging Session_IDs from the location office001, jpl and caltech, which have a charging time between 1.5 h and 3.5 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charging_cycle_session_ids(access_token, location, number_of_session , min_charging_time, max_charging_time):\n",
    "    \n",
    "    credentials = ('%s:%s' % (access_token, ''))\n",
    "    encoded_credentials = base64.b64encode(credentials.encode('ascii'))\n",
    "        \n",
    "    acn_session_ids = pd.DataFrame()\n",
    "    max_charging_time = timedelta(hours=max_charging_time)\n",
    "    min_charging_time = timedelta(hours=min_charging_time)\n",
    "    \n",
    "    for i in range(1,60):\n",
    "        req = urllib.request.Request(f'https://ev.caltech.edu/api/v1/sessions/{location}?&page={i}')\n",
    "        req.add_header('Authorization', 'Basic %s' % encoded_credentials.decode(\"ascii\"))\n",
    "        data = json.loads(urllib.request.urlopen(req).read())\n",
    "    \n",
    "        for j in range(0,25):       \n",
    "            if data['_items'][j]['doneChargingTime'] != None and data['_items'][j]['connectionTime'] != None:\n",
    "                charging_time = parser.parse(data['_items'][j]['doneChargingTime']) - parser.parse(data['_items'][j]['connectionTime'])\n",
    "                print(f\"session_id: {data['_items'][j]['_id']}, charging_time: {charging_time}\")\n",
    "\n",
    "                if max_charging_time > charging_time > min_charging_time: \n",
    "                    acn_session_ids=acn_session_ids.append({'session_id':data['_items'][j]['_id']}, ignore_index=True)\n",
    " \n",
    "                if len(acn_session_ids) == number_of_session:\n",
    "                    break\n",
    "            \n",
    "        if len(acn_session_ids) == number_of_session:\n",
    "            break            \n",
    "          \n",
    "    return acn_session_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e616d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "acn_data_office001_session = charging_cycle_session_ids(access_token, 'office001', 35, 1.5, 3.5)       \n",
    "acn_data_jpl_session = charging_cycle_session_ids(access_token, 'jpl', 35, 1.5, 3.5)       \n",
    "acn_data_caltech_session = charging_cycle_session_ids(access_token, 'caltech', 35, 1.5, 3.5)       \n",
    "\n",
    "acn_data_office001_session['location'] = 'office001'\n",
    "acn_data_jpl_session['location'] = 'jpl'\n",
    "acn_data_caltech_session['location'] = 'caltech'\n",
    "\n",
    "acn_data_session = pd.concat((acn_data_office001_session, acn_data_jpl_session, acn_data_caltech_session), axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99089c57",
   "metadata": {},
   "source": [
    "#### Read out loading time series of Session_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_charging_cycles_by_ids(access_token, session_ids):\n",
    "    \n",
    "    credentials = ('%s:%s' % (access_token, ''))\n",
    "    encoded_credentials = base64.b64encode(credentials.encode('ascii'))\n",
    "\n",
    "    EV_charge_ts = pd.DataFrame()\n",
    "\n",
    "    for index, row in session_ids.iterrows():\n",
    "        print(f\"{index}: session_id: {row['session_id']}, location: {row['location']}\")\n",
    "\n",
    "        req = urllib.request.Request(f\"https://ev.caltech.edu/api/v1/sessions/{row['location']}/ts/?where=_id=='{row['session_id']}'\")\n",
    "        req.add_header('Authorization', 'Basic %s' % encoded_credentials.decode(\"ascii\"))\n",
    "        data = json.loads(urllib.request.urlopen(req).read())\n",
    "        \n",
    "        session_ts = pd.DataFrame()\n",
    "        \n",
    "        if data['_items'][0]['chargingCurrent'] != None:\n",
    "        \n",
    "            session_ts=session_ts.append({'ts':data['_items'][0]['chargingCurrent']['current']}, ignore_index=True)\n",
    "            session_ts=pd.DataFrame(np.stack(session_ts['ts'].values).T, columns=[row['session_id']])\n",
    " \n",
    "            EV_charge_ts = pd.concat((EV_charge_ts, session_ts), axis=1) \n",
    "            \n",
    "    return EV_charge_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22843ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_charge_ts = concat_charging_cycles_by_ids(access_token, acn_data_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3097a",
   "metadata": {},
   "source": [
    "#### Sorting out charging processes with a charging power greater than 22kW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55890f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_out_column_by_value(data, greater_than):\n",
    "    \n",
    "    EV_charge_ts = pd.DataFrame()\n",
    "    \n",
    "    for i in range(data.shape[1]-1):\n",
    "        greater=False\n",
    "        for j in range(len(data)):\n",
    "            if data.iloc[j,i] > greater_than:\n",
    "                greater=True\n",
    "        if greater == False:\n",
    "             EV_charge_ts = pd.concat((EV_charge_ts, data.iloc[:,i]), axis=1)\n",
    "             \n",
    "    return EV_charge_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ed9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_charge_ts = sort_out_column_by_value(EV_charge_ts, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83cd09",
   "metadata": {},
   "source": [
    "#### Aggregate the sampling rate of the charging cycles from 4-secondly to hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_charge_ts = EV_charge_ts.groupby(EV_charge_ts.index // 900).mean().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dea497",
   "metadata": {},
   "source": [
    "#### Replace nan values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_charge_ts = EV_charge_ts[:4].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942f5ca",
   "metadata": {},
   "source": [
    "#### Group the households of the california dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1370fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "household_id=california.groupby('dataid').agg(dataid = ('dataid', 'first')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6a034",
   "metadata": {},
   "source": [
    "#### Adding daily EV charging events for every second household in the 'california' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(california)):\n",
    "    \n",
    "    if household_id.index[household_id['dataid']==california['dataid'][i]].tolist()[0] % 2 == 0 and california['local_15min'][i].hour == 0:\n",
    "        rand_EV = EV_charge_ts.columns[random.randrange(0, EV_charge_ts.shape[1])]\n",
    "        start_time = random.randrange(0, 24)\n",
    "        j = 0\n",
    "        print(f\"i: {i}, dataid {california['dataid'][i]}, rand_EV: {rand_EV}\")\n",
    "        \n",
    "        while  j < EV_charge_ts.shape[0] and i <= len(california):\n",
    "            california.at[i + j + start_time,'car1'] = EV_charge_ts.at[j,rand_EV]\n",
    "            print(f\"j: {j}, index: {i + j + start_time}\")\n",
    "            j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849d60b",
   "metadata": {},
   "source": [
    "#### Add loading events to the 'grid' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c169eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "california['grid'] = california[['grid','car1']].apply(lambda x: x['grid'] + x['car1'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32994729",
   "metadata": {},
   "source": [
    "#### Export datasets as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "\n",
    "newyork.to_csv(path + '1hour_data_newyork.csv', sep=',', encoding='utf-8', index=False)\n",
    "california.to_csv(path + '1hour_data_california.csv', sep=',', encoding='utf-8', index=False)\n",
    "austin.to_csv(path + '1hour_data_austin.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
